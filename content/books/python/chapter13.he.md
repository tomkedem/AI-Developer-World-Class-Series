---
title: "פרק 13 – ביצועים, זיכרון וקצת NumPy"
weight: 14
---
# **פרק 13 – ביצועים, זיכרון וקצת NumPy**
## למה ביצועים חשובים גם בפייתון
פייתון נחשבת לשפה איטית רק בעיני מי שמודד אותה **באופן שגוי**.
היא לא נועדה לנצח בתחרות על **האלגוריתם המהיר ביותר**,
אלא לאפשר למפתח **חופש לחשוב, להתנסות ולבנות במהירות**.  

אלא שבעולם ה-**AI**, שום דבר כבר איננו קטן.
כל טקסט עשוי להכיל **ג׳יגה-בייטים של מידע**,
כל **מערך נתונים (dataset)** מתנהג כמו יקום שלם,
ומודל אחד תמים לכאורה עלול לצרוך **עשרות ג׳יגה-בייטים של זיכרון**.
לא דרוש הרבה כדי שמחשב נייד יתחיל להשמיע **קולות של מנוע סילון** באמצע האימון.  

במילים אחרות: הבעיה אינה טמונה בפייתון עצמה,
אלא **באופן שבו משתמשים בה**.
כאשר מתייחסים אליה כשפה סקריפטית בלבד, היא מתנהגת בהתאם;
אך כשמשלבים בה את **הכלים הנכונים**
NumPy, Generators, ו-Profilers 
היא הופכת ל-**כלי הנדסי של ממש**.  

מטרת הפרק הזה איננה “לסחוט עוד שלושה אחוזים של מהירות”,
אלא להבין **היכן באמת מתבזבז הזמן**,
מה גורם **לעומס על הזיכרון**,
ואיך לגרום לפייתון לעבוד **בצורה חכמה ויעילה יותר**.
בסופו של דבר, ביצועים אינם רק עניין של מספרים 
הם ההבדל בין **קוד שמגיב מיידית**,
לבין **קוד שמזכיר לך שהמאוורר במחשב עדיין עובד**.

## מדידת זמן ריצה – כי ניחושים לא משפרים ביצועים
לפני שמייעלים קוד, צריך לדעת **מה באמת איטי**.
המודול timeit נועד בדיוק לזה. 
למדוד זמן ריצה בצורה אמינה, נקייה ובלתי תלוית-מערכת.
```python
import timeit

code = "result = [x**2 for x in range(10_000)]"

print(timeit.timeit(code, number=100))
```
timeit מריץ את הקוד שוב ושוב ומחזיר **ממוצע זמן ריצה מדויק**.
כך ניתן להשוות בין גרסאות של פונקציה ולראות איזו מהן **באמת מהירה יותר**, לא לפי תחושת בטן, אלא לפי נתונים.  

דוגמה קטנה:
```python
setup = "nums = list(range(1000))"
v1 = "sum([x**2 for x in nums])"
v2 = "sum(x**2 for x in nums)"  # Generator does not create a full list in memory

print(timeit.timeit(v1, setup=setup, number=1000))
print(timeit.timeit(v2, setup=setup, number=1000))
```
במבחן אמיתי, תופתע לגלות שהגרסה הקצרה יותר **לא רק נקייה וברורה יותר**, אלא גם **מהירה וחסכונית בזיכרון** 
בזכות השימוש ב-**Generator Expression**
שמחשב ערכים תוך כדי תנועה במקום ליצור רשימה שלמה מראש.
מדידת זמן ריצה היא לא רק שלב לפני אופטימיזציה, היא כלי למחשבה.
ברגע שמודדים באופן עקבי, מתחילים לזהות תבניות:
אילו פעולות באמת יקרות, ואילו רק נראות כך.
מפתח שמודד, כותב קוד מדויק יותר, ולא מהיר “במקרה”.

**ניתוח פרופיל: לזהות את צוואר הבקבוק**  
לפעמים הקוד כולו מרגיש “איטי”, אבל האמת היא שפונקציה אחת גונבת את כל הזמן.
כדי למצוא אותה, יש את cProfile:
```python
import cProfile

def compute():
    return sum(i * i for i in range(100_000))

cProfile.run("compute()")
```
הפלט יגיד לך כמה פעמים כל פונקציה נקראה וכמה זמן היא לקחה.
אם אחת מהן אחראית ל-80% מהזמן, מצאת את הבעיה.
רוצה לראות כמה זה יפה? התקן snakeviz:
```text
pip install snakeviz
python -m cProfile -o out.prof myscript.py
snakeviz out.prof
```
ותקבל גרף צבעוני של זמן הריצה שלך.

## עבודה חכמה עם זיכרון – לא כל דבר צריך רשימה
לפעמים הבעיה אינה המהירות, אלא **הזיכרון**.
אפשר לכתוב פונקציה שרצה מהר, אבל אם היא יוצרת ברשימה אחת מיליון איברים,
המחשב שלך עלול “להתנפח” עד כדי האטה או קריסה.
כאן נכנסים לתמונה **Generators**  
פונקציות שמחזירות ערכים **אחד-אחד**, לפי הצורך,
במקום לבנות רשימה שלמה מראש.
```python
def squares():
    for i in range(1_000_000):
        yield i ** 2

for n in squares():
    if n > 100:
        break
```
הפונקציה הזו לא שומרת מיליון ערכים בזיכרון.
היא פשוט מחשבת כל ערך כשצריך אותו 
וזה חוסך המון זיכרון, בלי לפגוע בפשטות הקוד.
אפשר לחשוב על Generator כעל **צינור שמזרים נתונים**,
במקום **דלי שמחזיק הכול מראש**.  

ובעולם ה-**AI**, זו לא רק יעילות, זו לעיתים **תנאי הכרחי**:
כך אפשר לקרוא datasets עצומים ולנתח אותם בהדרגה,
מבלי להעמיס את כל המידע על הזיכרון בבת אחת.

## NumPy בפועל – מערכים ופעולות וקטוריות חכמות
אם אתה עובד עם מספרים, טבלאות או מטריצות. תכיר את **NumPy**.
זו הספרייה שהפכה את פייתון משפה נוחה אך איטית לשפה שיכולה לרוץ כמעט כמו C.  

איך היא עושה את זה?
פשוט:
במקום לשמור רשימת אובייקטים בזיכרון, כמו שפייתון עושה בדרך כלל,
NumPy שומרת **בלוק אחד צפוף של נתונים** (ב-C).
כשאתה מבצע חישוב, היא מפעילה את הפעולה על כל הבלוק בבת אחת 
בלי לולאה אחת בפייתון. 
```python
import numpy as np

a = np.arange(1_000_000)
b = a * 2  # vectorized operation many times faster than a regular loop
```
במקום לעבור איבר-איבר, המעבד מבצע את כל ההכפלה “בבאטץ’ אחד”.
זו בדיוק **וקטוריזציה (Vectorization)** 
היכולת לבצע פעולה אחת על מערך שלם,
באמצעות הוראות מעבד שמטפלות בכמה ערכים בו-זמנית.

**דוגמה**
```python
import numpy as np

x = np.array([1, 2, 3])
y = np.array([4, 5, 6])

print(x + y)      # [5 7 9]
print(x * y)      # [ 4 10 18]
print(np.mean(x)) # 2.0

m = np.random.rand(3, 3)
print(np.linalg.inv(m))  # matrix inverse
```
במבט ראשון זה נראה כמו קוד רגיל.
חיבור רשימות, כפל איברים, חישוב ממוצע.
אבל מתחת לפני השטח,  NumPy **לא רצה בלולאה אחת**.
היא שומרת את כל הנתונים במערך צפוף (array) בזיכרון,
ומעבירה את הפעולה כולה לקוד C יעיל,
שמבצע אותה על כל הנתונים יחד, בלי הפרשנות האיטית של פייתון.
כך זה נראה בגרסה "רגילה" לעומת גרסה וקטורית:
```python
# regular version
result = []
for i in range(len(x)):
    result.append(x[i] + y[i])

# vectorized version NumPy
result = x + y
```

התוצאה זהה, אבל זמן הריצה שונה לגמרי.
**למה זה כל כך מהיר**
במילים פשוטות:
- **רשימות פייתון:** אוסף של אובייקטים נפרדים, כל אחד במקום אחר בזיכרון.
- **מערכי :NumPy** בלוק רציף וצפוף של נתונים שמיוצגים כמספרים “טהורים”.  

המעבד יודע לגשת ישירות לבלוק הזה ולעבד אותו בפעולה אחת (SIMD),
מה שמדלג על כל ה-overhead של פייתון 
ובמקרים רבים, מביא למהירות גבוהה פי 50–100.
זה לא טריק, זו **ארכיטקטורה חכמה**:
לתת לשפת פייתון את המוח של C, בלי לאבד את הפשטות של פייתון.

## דוגמה מרכזית: תדירויות מילים (נאיבי מול NumPy)
ניקח תרגיל קלאסי: ספירת תדירויות מילים.  

**גישה נאיבית:**  

```python
from collections import Counter

def word_freq_naive(words: list[str]) -> dict[str, int]:
    return dict(Counter(words))
```
**גישה וקטורית עם NumPy:**
```python
import numpy as np

def word_freq_numpy(words: list[str]) -> dict[str, int]:
    arr = np.array(words)
    unique, counts = np.unique(arr, return_counts=True)
    return dict(zip(unique, counts))
```
ב-dataset קטן זה לא משנה. אבל כשיש לך מיליון מילים,  הגרסה של NumPy תרוץ פי 5–10 מהר יותר, בלי לשנות שורה של לוגיקה.

## Best Practices
- **מדוד לפני שאתה משפר** בלי נתונים, זו רק אינטואיציה.
- **השתמש ב-NumPy** לכל חישוב מתמטי רציני.
- **השתמש ב-generators** כשקוראים קבצים או עובדים עם זרמים גדולים.
- **הימנע מהעתקות מיותרות של נתונים.**
- **תעדף וקטוריזציה** על פני לולאות.
**תעדף פשטות על פני “אופטימיזציה חכמה”**    

רק אם יש בעיה אמיתית, פותרים אותה.

## סיכום – איך להגיע לביצועים גבוהים בפייתון
פייתון לא נועדה לנצח בתחרות על המהירות הגולמית.
אבל עם קצת הבנה של הכלים הנכונים, היא מסוגלת לרוץ מהר, ממש מהר.
מדוד עם timeit, חפור עם cProfile,
חסוך בזיכרון עם generators, והאץ כל חישוב עם NumPy.
התוצאה: קוד נקי, קריא, ועם ביצועים שמפתיעים גם את הספקנים הכי גדולים.  


כי בסוף, לא מדובר בלהיות “מהיר”, אלא בלהיות **יעיל**.
וזה בדיוק מה שמבדיל בין מתכנת לפייתוניסט אמיתי.