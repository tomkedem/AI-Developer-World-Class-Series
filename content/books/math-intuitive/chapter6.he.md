---
title: "פרק 6 - נורמה ומרחק - מודדים את העולם"
weight: 7
---
# פרק 6 -- נורמה ומרחק -- מודדים את העולם

## מה זה "אורך" של וקטור

אם פרק 5 עסק בשאלה איך מייצגים דברים כוקטורים,
הפרק הזה עוסק בשאלה הבאה:
**איך מודל יודע כמה הוקטור הזה "גדול", "חזק" או "קיצוני"?**

וזו בדיוק הנורמה.

**מהי נורמה?**

נורמה היא מספר אחד
שמסכם את "הגודל" של הוקטור.

אפשר לחשוב עליה כעל אורך.
אם תצייר וקטור על לוח כקווים,
הנורמה היא האורך של הקו.

בפייתון, אם יש לנו וקטור:
```py
v = [3, 4]
```
הנורמה שלו היא
5
כי זה האורך של הקו מהנקודה (0,0) לנקודה (3,4).

אצל מודלים הרעיון זהה
רק שהוקטורים ארוכים בהרבה
ולכן האורך שלהם מספר משהו חשוב.

**למה אכפת למודל מהאורך?**

כי נורמה מציגה למודל
כמה חזק או קיצוני אובייקט מסוים ביחס לאחרים.

לדוגמה

-   משתמש עם פעילות ענקית יקבל וקטור ארוך יותר

-   תמונה שיש בה המון פרטים לפעמים יוצרת וקטור ארוך יותר

-   מילה שמופיעה תמיד בסביבה "חזקה" תקבל וקטור שאורכו שונה ממילים פחות
    משמעותיות

-   בנתונים שמתנהגים בצורה קופצנית ולא עקבית, חלק מהוקטורים קופצים
    באורך בצורה לא יציבה הנורמה הופכת את העולם המרובה ממדים למספר אחד
    שקל להשוות.

**למה "אורך" עוזר למערכת להבין דברים?**

כי כשאתה משווה אורכים
קבלת אינטואיציה על "כמה הדבר הזה גדול יחסית לאחרים".

לא צריך מתמטיקה כבדה.
צריך את ההבנה הפשוטה הזו:
**נורמה עוזרת למודל להבין את עוצמת המידע.**

בפרקטיקה
הנורמה משמשת כדי

-   לנרמל דאטה

-   להבין חריגות

-   להשליך נקודות שנמצאות "רחוק מדי"

-   לקבוע גבולות במערכות זיהוי אנומליות

-   להכין את הוקטורים להשוואה אמיתית

ובפרקים הבאים של הספר
היא תהיה אחת המילים שיחזרו הכי הרבה.

## איך מודלים מודדים כמה דברים דומים או שונים

אחרי שהבנו מהו האורך של וקטור, מגיעה שאלה בסיסית שכל מודל חייב להתמודד
איתה:
**איך יודעים אם שני אובייקטים דומים או שונים, כשהכול מיוצג
כוקטורים?**

בגלל שכל מודל עובד על רשימות מספרים, הוא צריך דרך להשוות בין שתי נקודות
במרחב ולתרגם את ההשוואה הזאת ל\"קרבה\" או \"מרחק\".

**הצעד הראשון: מרחק**

המדד הכי פשוט לדמיון הוא **מרחק בין וקטורים**.
העיקרון מאוד אינטואיטיבי:

-   מרחק קטן ← הוקטורים **דומים**

-   מרחק גדול ← הוקטורים **שונים**


דוגמה:
```py
import numpy as np

v1 = np.array([1, 2])
v2 = np.array([2, 3])

distance = np.linalg.norm(v1 - v2)
print(distance)
```

המספר שמתקבל הוא המרחק הגיאומטרי ביניהם.

**למה מרחק הוא כלי שימושי?**

כי הוא נותן למודל מדד ישיר לשאלה
**\"כמה שני דברים רחוקים אחד מהשני?\"**

וזה שימושי במיוחד ב:

-   מערכות המלצה

-   זיהוי תמונות

-   חיפוש דמיון בין מסמכים

-   איתור חריגות

-   קיבוץ נתונים דומים

מודל מקבל שתי רשימות של מספרים, מודד את המרחק ביניהן, ומסיק אם מדובר
באותו סוג של מידע או לא.

**אבל מרחק הוא רק חלק מהסיפור**

כאן מגיעה הנקודה הקריטית:
**מרחק לא יודע להבין משמעות.**

שני משפטים יכולים להיות שונים לגמרי מבחינת המילים,
אבל מאוד דומים מבחינת המשמעות.
במצב כזה המרחק ביניהם יכול להיות גדול מדי, למרות שהם \"אומרים\" את אותו
הדבר.

מצד שני, שני משפטים שמכילים מילים דומות
יכולים להיות קרובים במרחב המספרי
למרות שהמשמעות שלהם שונה לחלוטין.

במילים פשוטות:
**מרחק מודד שונות גיאומטרית, לא שונות רעיונית.**

**למה זה בעייתי במיוחד בטקסט?**

כי טקסט מבוסס על **משמעות**, **הקשר**
ו**כוונה**.
שתי מילים יכולות להיראות קרובות מאוד מבחינה מספרית,
אבל להיות שונות לגמרי בתוכן.
ודרך אחרת -- מילים שונות יכולות לשאת אותה משמעות.

לכן מודלים צריכים יותר מאשר מרחק.
הם צריכים כלי שמזהה **כיוון משותף** בין וקטורים
ולא רק את \"הגודל\" של ההפרדה ביניהם.

זה בדיוק מה שמוביל אותנו לשיטה שחייבים להכיר בעולם
ה-NLP:
מדידת זווית בין וקטורים, או במילים פשוטות -- **דמיון
קוסינוס**.

בחלק הבא נבין למה מרחק לבדו לא מספיק, ואיך זווית בין וקטורים נותנת
למודל הבנה הרבה יותר מדויקת של משמעות.

## למה מרחק לא מספיק בניתוח טקסט

מרחק הוא כלי שימושי למדידת דמיון, אבל בעולם של טקסט הוא פשוט לא
מספק.
כדי להבין למה, צריך לזכור ש**טקסט הוא משמעות**, ולא רק
אוסף של מילים.
כשמודל מקבל משפט, הוא צריך להבין לא רק אילו מילים מופיעות בו, אלא גם מה
הן מנסות להגיד.

ופה מרחק כבר מתחיל לחרוק.

**דוגמה שממחישה את הבעיה**

שני המשפטים
**\"אני מאחר לעבודה\"**
ו
**\"אני מתקשה להגיע בזמן\"**
משתמשים במילים שונות, אבל המשמעות שלהם כמעט זהה.

לעומת זאת, המשפטים
**\"אני אוהב קפה\"**
ו
**\"אני אוהב לשרוף גשרים\"**
משתפים חלק מהמילים, אבל המשמעויות שלהם רחוקות לגמרי.

מרחק גיאומטרי לא יודע לעשות את ההבחנה הזאת.
הוא רואה **מספרים**, לא רעיונות.

זה אומר שוקטורים של שני משפטים בעלי משמעות דומה יכולים להיות רחוקים
מדי,
ושניים בעלי משמעות שונה יכולים להיות קרובים מדי.
במילים אחרות:
**מרחק מתייחס רק לפער במספרים, לא לתוכן שמסתתר מאחוריהם.**

**למה זה קורה?**

כי מרחק עונה על שאלה אחת בלבד:
**\"כמה הוקטורים מתרחקים אחד מהשני במרחב?\"**

אבל הוא לא עונה על שאלות כמו:

-   האם הכיוון שלהם דומה?

-   האם הם מצביעים על אותו רעיון?

-   האם הם מתארים אותה כוונה?

בטקסט זה קריטי, כי שני משפטים שנראים שונה מבחינה צורתית יכולים להיות
כמעט זהים מבחינה רעיונית.

**מודלים צריכים כלי נוסף שמבין כיוון**

כשמדברים על טקסט, השאלה החשובה היא לא רק "כמה רחוק",

אלא גם
**"לאיזה כיוון הוקטורים מצביעים?"**

כיוון - מספר למודל, האם שני משפטים \"מסתובבים סביב אותו רעיון\", גם אם
המרחק ביניהם גדול.
זו הסיבה שמערכות NLP ותהליכי הבנה סמנטית כמעט תמיד משתמשים
במדידת זווית בין וקטורים ולא רק במרחק.

המדד הזה נקרא **דמיון קוסינוס**, והוא אחד הכלים החשובים
ביותר להבנת משמעות בשפה.

בחלק הבא נעמיק בכלי הזה ונראה איך הוא פותר את כל הבעיות שמרחק לא מצליח
לפתור.
