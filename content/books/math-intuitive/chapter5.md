---
title: "פרק 5 - וקטורים - הלב של כל מודל"
weight: 6
---
# פרק 5 -- וקטורים -- הלב של כל מודל

## איך מציגים אובייקט כסדרה של מספרים

אם יש משהו אחד שבאמת משנה את הדרך שבה מפתח מבין AI, זה
הרעיון שכל אובייקט בעולם -- טקסט, תמונה, משתמש, מוצר,
אירוע -- יכול להפוך לוקטור.
זאת אומרת: **רשימה מסודרת של מספרים**.

כדי להבין מודלים מודרניים, צריך להבין את המשפט הבא:

**AI לא עובד על תוכן. הוא עובד על מספרים שמייצגים תוכן.**

וזה בדיוק מה שנותן לוקטורים את הכוח שלהם.

**מה זה בכלל וקטור?**

זה פשוט מאוד.
וקטור הוא רשימה של מספרים.
לא מטריצה, לא אובייקט מסובך.
רשימה.

לדוגמה:

\[0.2, 1.7, 3.4\]

או

\[0.01, 0.43, -0.12, 0.77, 0.91\]

וקטור יכול להיות קצר או ארוך מאוד.
במודלים גדולים, האורך נמדד לפעמים באלפי ערכים.

**למה זה מעניין אותנו?**

כי וקטור הוא הדרך שבה מודל **מבין** דברים.
כשאומרים למודל \"זה משפט חיובי\" או \"זה חתול\",
אי אפשר לתת לו תמונה או טקסט ישירות.
צריך לתת לו **מספרים**.

והמספרים האלו הם וקטור.

**איך אובייקט הופך לוקטור?**

אפשר לחשוב על זה כעל תרגום.
אובייקט מגיע מבחוץ -- תמונה, מילה, משתמש, מה שלא
יהיה
והמודל צריך דרך לייצג אותו בצורה מתמטית.

הרעיון פשוט:
לוקחים את התכונות החשובות וממירים אותן למספרים.

דוגמאות בסיסיות:

-   צבע של פיקסל הופך לערך בין 0 ל-255

-   מילה הופכת לרשימת מספרים שמייצגים משמעות

-   משתמש הופך לקבלת וקטור של התנהגויות

-   מוצר הופך לערכים שמייצגים תכונות שנלמדו מדאטה

עכשיו נסביר כל דוגמה בצורה פשוטה וברורה.

**צבע של פיקסל הופך למספר**

בכל תמונה יש פיקסלים.
למודל אין מושג מה זה "אדום" או "כחול".
אז כל צבע בודד מקבל **מספר מ 0 עד 255**.

0 זה כהה.
255 זה בהיר.
וביניהם כל הדרגות של הצבע.

כל פיקסל = מספר.
ככה המודל "רואה" תמונה.

**מילה הופכת לרשימת מספרים שמייצגים משמעות**

כאן זה הכי מבלבל אנשים.
אין "מילים" בתוך מודל.
אין אותיות.
הכול הופך ל **וקטור** -- רשימת מספרים.

למשל:
\"המבורגר\" הופך לרשימה כגון:
\[0.12, 0.83, 1.44, ...\]

אבל הרשימה הזו לא מייצגת "אותיות".
היא מייצגת **משמעות**:
אוכל, טעם, מסעדה, שומן, טקסט, הקשר.

המספרים נוצרים מתהליך אימון, לא מניחוש ידני.

כל מילה = רשימת מספרים.

**משתמש הופך לוקטור של התנהגויות**

המודל לא עובד עם "פרופיל משתמש".
הוא עובד עם **מספרים** שמייצגים את הדפוסים של אותו אדם:

-   כמה פעמים הוא נכנס לאפליקציה

-   באיזה שעות

-   באיזה מסכים הוא משתמש

-   מה משך הפעולה

כל זה הופך לשורה של מספרים, כגון:
\[3.1, 0.8, 12.4, 0.02 ...\]

זה לא "מי הוא" -- זה **איך הוא מתנהג** מבחינת דפוס.

**מוצר הופך לערכים שמייצגים תכונות**

אם אתה מוכר מוצרים,
למודל לא משנה "איך המוצר נראה".
הוא צריך מספרים שייצגו:

-   מחיר

-   קטגוריה

-   פופולריות

-   תדירות קנייה

-   קשר למוצרים אחרים

המודל לוקח את כל זה והופך את המוצר לוקטור כגון:
\[0.51, 2.3, 0.12, 15.4 ...\]

ככה הוא משווה בין מוצרים.

**מה המשותף בין כל הדוגמאות?**

הכול הופך למספרים.
לא כי מפתחים אוהבים מתמטיקה,
אלא כי זו **השפה שהמודל יודע לדבר**.

ברגע שאובייקט בעולם מקבל ייצוג מספרי,
המודל יכול להשוות, למדוד, לזהות דפוסים ולהפיק תחזיות.

הוקטור הוא בעצם **קלף זיכרון** של המודל.
הוא מספר למודל מה הוא ראה.

**
**

**למה זו נקודת מפנה בהבנה של AI?**

כי ברגע שמבינים שכל אובייקט הופך לוקטור
מבינים גם:

-   איך מודלים משווים בין דברים

-   איך הם מחשבים דמיון

-   למה דברים שונים מתבלבלים לפעמים

-   למה שינוי קטן בנתונים יכול לייצר שינוי גדול בתוצאה

-   ולמה כל כך חשוב שהוקטורים יהיו נקיים ומייצגים

וקטור הוא לא רק "רשימת מספרים".
הוא **הזהות המתמטית** של כל דבר שהמודל עובד איתו.

בחלק הבא נבין למה כמעט כל AI בעולם, קטן וגדול, עובד בדיוק
עם המבנה הזה.


## למה כמעט כל AI עובד על וקטורים

אחרי שהבנו שוקטור הוא פשוט רשימה של מספרים שמייצגת
אובייקט,
עולה שאלה טבעית:
**למה כל עולם ה-AI עובד דווקא עם וקטורים?**

יש לזה שלוש סיבות עמוקות שמחברות בין מתמטיקה, יעילות, והדרך שבה מודלים
לומדים דפוסים.

1.  **וקטורים מאפשרים למודל למדוד דמיון**

> זה הרעיון הכי חשוב.
> כדי שמודל יבין ש:

-   שני משפטים דומים

-   שתי תמונות מציגות אותו אובייקט

-   שני משתמשים מתנהגים בצורה קרובה

> הוא צריך דרך למדוד קרבה.
>
> וקטור מאפשר לעשות בדיוק את זה
> על ידי חישוב של:

-   מרחק

-   זווית

-   דמיון

> בין רשימות של מספרים.
>
> לדוגמה, אם שני משפטים מיוצגים כוקטורים קרובים
> המודל יפרש אותם כבעלי משמעות דומה.
> זה הבסיס של NLP מודרני.

2.  **וקטורים מאפשרים לבצע חישובים מהירים מאוד**

> המתמטיקה על וקטורים
> ממוצעים, סכומים, מכפלות, מרחקים
> היא מהירה במיוחד לחישוב על חומרה מודרנית.
> זה חשוב כי מודלים מבצעים מיליארדי פעולות כאלה.
>
> וקטורים עובדים מצוין עם
> GPU, TPU וכל מנוע שמקבל עבודה על מספרים.
>
> זו אחת הסיבות שמודלים גדולים בכלל אפשריים.

3.  **וקטורים מאפשרים למודל \"ללמוד\" תכונות בעצמו**

> במערכות ישנות היינו צריכים לבחור תכונות ידנית.
> בינה מלאכותית מודרנית לומדת תכונות לבד
> ומכניסה אותן לתוך הוקטור.
>
> זה אומר שהוקטור מייצג, לא רק מידע גולמי
> אלא גם משמעות שהמודל למד מתוך דוגמאות.
>
> המילה \"כלב\" תקבל וקטור שמתקרב
> למילים כמו \"גור\", \"לנבוח\", \"חיה\"
> ומתרחק ממילים כמו \"חלון\", \"פינגווין\" או \"שולחן\".
>
> זה לא קסם.
> זה פשוט מבנה שמאפשר למודל לקלוט הקשרים מתוך מספרים.

4.  **וקטור הוא מבנה אוניברסלי**

> תמונה, משפט, משתמש, מוצר, אירוע
> הכול נהיה וקטור.
> ואז המודל לא צריך להתאים את עצמו לכל סוג של מידע.
> הוא תמיד עובד על אותו פורמט:
> **מספרים.**
>
> בגלל זה מודלים יכולים לעבור בין
> טקסט
> תמונה
> אודיו
> קוד
> וגם בין דאטה מובנה ולא מובנה.
>
> הבסיס תמיד אותו בסיס: וקטור.

## איך טקסט, משתמש או תמונה הופכים לוקטור

עכשיו כשהרעיון של וקטורים ברור, מגיעה השאלה המעשית:
איך אובייקטים אמיתיים, כאלה שאנחנו רואים במערכות יום יום, הופכים
לרשימות מספרים שמודל יכול לעבוד איתן?

נפרק את זה לשלושה סוגים נפוצים של מידע.

**טקסט ← וקטור של משמעות**

זו אחת ההמרות הכי מעניינות.

בתחילת הדרך
היינו ממירים כל מילה למספר לפי המיקום שלה במילון.
זה לא עבד טוב, כי מילים שונות לחלוטין קיבלו מספרים בלי קשר למשמעות
שלהן.

במודלים מודרניים
כל מילה וכל רצף מילים מקבל וקטור שמייצג את המשמעות שלו.
שתי מילים שמופיעות בהקשרים דומים
מקבלות וקטורים קרובים.

לדוגמה, המילים
לקוח, משתמש, צרכן
יהיו קרובות יחסית.
אבל המילה מנורה תהיה רחוקה מהן.

המודל לא \"מבין\" עברית.
הוא רואה מספרים שמספרים לו מי קרוב למי.

**משתמש ← וקטור של התנהגות**

גם משתמשים הופכים לוקטורים.

הוקטור שלהם יכול להכיל למשל

-   כמות ביקורים

-   סוגי פעולות

-   זמנים אופייניים

-   קטגוריות שנצפו

-   אורך סשנים

-   דפוסי מעבר בין מסכים

המערכת לא צריכה לדעת מי המשתמש בפועל.
היא רק צריכה וקטור שמייצג את ההתנהגות שלו.

שני משתמשים שונים לחלוטין
יכולים לקבל וקטורים דומים
אם הם מתנהגים בדרך דומה.
וזה בדיוק מה שמאפשר המלצות חכמות.

**תמונה ← וקטור של מאפיינים חזותיים**

בכל תמונה יש אלפי פיקסלים.
אי אפשר לעבוד ישירות עם כל הפיקסלים.
לכן המודל מעבד את התמונה בשכבות ומייצר וקטור מאפיינים.

הוקטור הזה יכול לייצג

-   קווים

-   צבעים

-   טקסטורות

-   צורות

-   חלקים של אובייקטים

-   דברים שלא תמיד בני אדם שמים לב אליהם

למשל
כל התמונות של חתולים תקבלנה וקטורים קרובים
גם אם הצבע שונה
גם אם הזווית שונה
גם אם הרקע שונה.

שוב
המחשב לא \"רואה חתול\"
הוא רואה וקטור שמאפיין תבנית שמתאימה לחתול.

**למה הכול עובד אותו דבר?**

זה היופי.
כיוון שהכול מתורגם לוקטורים
מודלים יכולים לעבוד על סוגים שונים של מידע
באותה לוגיקה.

הם לוקחים וקטורים
משווים
מודדים מרחקים
מזהים דפוסים
לומדים הקשרים
ונותנים תחזיות.

הבסיס תמיד אותו בסיס.

> 
> 
> 
