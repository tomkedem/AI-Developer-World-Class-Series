---
title: "פרק 3 - הסתברות שמדברת בשפה של מתכנת"
weight: 4
---
# פרק 3 -- הסתברות שמדברת בשפה של מתכנת

## הסתברות כתדירות בעולם אמיתי

לפני שמדברים על נוסחאות או סמלים, חשוב להבין משהו פשוט:
הסתברות היא לא מתמטיקה מופשטת.
היא תיאור של **מספר דברים שקורים במציאות**.

כשאומרים "הסתברות של 0.2", הרבה אנשים רואים סתם מספר.
אבל מי שמפתח מערכות מבין שזה אומר:
"זה קורה בערך 20 אחוז מהפעמים".

וזהו.
אין פה קסם.

**הסתברות היא בעצם ספירה**

אם מתוך 100 בקשות לשרת:
20 נכשלות
80 מצליחות

אז ההסתברות לכשלון היא:
**20 מתוך 100 ← 0.2**

השפה הזו טבעית הרבה יותר ממונחים כמו "אירועים", "מרחבי דגימה" או
"התפלגות".
מפתח לא צריך את כל זה.
הוא צריך להבין **מה קורה בדאטה**.

**הסתברות משקפת תדירות**

אם 7 מתוך 10 משתמשים לוחצים על כפתור ← 0.7
אם רק פעם אחת מתוך 50 מגיעה בקשה חריגה ← 0.02
אם חצי מהתגובות למודל חיוביות ← 0.5

המספרים הם תוצאה של **ספירה**, לא של מתמטיקה
גבוהה.

**למה זה חשוב בעבודה עם AI?**

כי מודלים לא "מנחשים".
הם **משווים תדירויות בעולם שהם ראו**, ומייצרים תחזיות
בהתאם.

לדוגמה:
אם מודל טקסט ראה שב-90 אחוז מהמקרים המילה "טוב" מגיעה אחרי המילה
"היה"
הוא ייטה להשלים "היה טוב".

זה לא חוכמה.
זה **סטטיסטיקה פשוטה**.

**בלי תדירות -- אין למידה**

כדי שמודל ילמד דפוסים, הוא חייב לראות אותם חוזרים שוב
ושוב.
אם הדאטה נדיר, מפוזר או בלתי עקבי
המודל לא ילמד כלום, גם אם הוא גדול וחכם.

זאת ההבנה הראשונה שאתה חייב כדי לדבר "הסתברות של מודל":
לא מספרים, לא נוסחאות.
רק כמה פעמים משהו קורה.

## איך מייצגים תרחישים בצורה פשוטה

אחרי שמבינים שהסתברות היא בעצם תדירות, מגיעה השאלה
הפרקטית:
**איך מייצגים תרחיש בצורה שהמודל מסוגל להבין וללמוד ממנו?**

מבחינת המודל, "תרחיש" הוא פשוט רגע שבו משהו קורה.
הוא לא יודע אם זה "משתמש לוחץ על כפתור", "מייל שמגיע", או "משפט
שמסתיים".
מה שהוא צריך זה ייצוג מספרי שנותן תמונה ברורה של מה קורה ומה **קרה
בעבר**.

**איך אנחנו מייצגים תרחישים?**

בדרך כלל בצורה הכי פשוטה שיש:
**ספירה של כמה פעמים כל דבר קורה.**

זה יכול להיות בטבלה, ברשימה, או במערך של
NumPy.
העיקרון תמיד זהה:
המודל לומד מתוך **תדירויות**.

לדוגמה, ניקח מערכת שמזהה האם הודעה היא ספאם.
נניח שאנחנו סופרים כמה פעמים מילה מסוימת הופיעה בהודעות שסומנו כספאם או
כלגיטימיות:

| מילה | מופעים בספאם | מופעים בהודעות רגילות |
|------|---------------|------------------------|
| free | 42            | 3                      |
| urgent | 17         | 1                      |
| hello | 2          | 58                     |

הטבלה הזו מספרת למודל הרבה יותר ממה שנדמה:

-   המילה free כמעט תמיד מופיעה בספאם

-   המילה hello מופיעה בעיקר בהודעות רגילות

-   המילה urgent מוטה חזק לספאם, אבל לא ב-100
    אחוז

בלי להבין הסתברות -- פשוט מסתכלים על המספרים ורואים את
התמונה.

**תרחיש = הקשר**

אבל לא רק "מה מופיע", אלא גם "איפה זה מופיע".

למשל, אם משתמש לוחץ על כפתור רק כשהוא מגיע מדפדפן מסוים, זה תרחיש
חוזר.
אם בקשות מסוימות ל-API כושלות בעיקר בלילה, זה תרחיש
חוזר.
אם המילה "בעיה" מופיעה 80 אחוז מהפעמים לפני המילה "דחוף", זה תרחיש
חוזר.

הסתברות היא כלי שמחבר אותך לאינטואיציה הזו.

**למה זה חשוב בעולם האמיתי?**

כי כשאנחנו מפתחים מערכת ML או אפילו כשאנחנו מנתחים ביצועים
של מודלים גדולים
אנחנו תמיד עובדים סביב תרחישים:

-   "מה הסיכוי שהתגובה הזו נכונה?"

-   "מה ההסתברות שהמשתמש ינטוש?"

-   "כמה פעמים זה קורה ביחס לכלל המקרים?"

-   "האם זה דפוס או רעש?"

וכשמבינים איך לייצג תרחישים פשוטים
גם הדברים המורכבים יותר נהיים הרבה יותר ברורים.


## דוגמאות: למה דברים קורים יותר או פחות

ברגע שמבינים שהסתברות היא בעצם תדירות, אפשר להתחיל לראות דפוסים כמעט
בכל מערכת.
ולפעמים הדפוסים האלה מסבירים לנו דברים שנראים "מוזרים" מבחוץ, אבל
הגיוניים לגמרי מבפנים.

**דוגמה 1 -- למה מודל טועה שוב ושוב באותה נקודה**

נניח שיש לך מערכת שממליצה על כתבות.
בכל פעם שמשתמש לוחץ על כתבה בנושא "כסף", המודל מזהה את זה כתכונה
חיובית.
אבל בפועל, המשתמש לוחץ על כתבות כאלה רק בימי ראשון בבוקר.

כאן יש דפוס:
**ימי ראשון ← סיכוי גבוה יותר ללחיצה.**

מי שלא מסתכל על תדירויות מפספס את זה.
המודל, לעומת זאת, רואה שזה "קורה הרבה בימי ראשון", ולכן הוא לומד לקשר
בין שני הדברים -- גם אם בכלל לא התכוונת שזה יהיה פיצ'ר.

**דוגמה 2 -- למה המילה free נחשבת מסוכנת
בספאם**

הסתכלנו על טבלה עם ספירות, אבל בוא נראה את זה אינטואיטיבית:

אם מילה מסוימת מופיעה **14 פעמים בספאם**
**ופעם אחת בלבד** בהודעה רגילה
אין צורך בשום נוסחה.
גם בן אדם היה מסמן את זה כמחשיד.

זו הסתברות פשוטה:
זה קורה כאן הרבה, וזה כמעט לא קורה שם.

מודלים לומדים בדיוק כך.

**דוגמה 3 -- למה מערכת רמזורים "מתחרפנת" בשעות מסוימות**

אם רואים שבדרך כלל מגיעות 300 מכוניות בשעה,
ופתאום ברצף של 5 דקות מגיעות 200 מכוניות
זה דפוס שמערכת בקרה חייבת ללמוד ממנו.

במילים אחרות:
**כשמשהו קורה הרבה יותר מהרגיל -- ההסתברות שלו גבוהה באותו
רגע.**
וכשמשהו קורה פחות מהרגיל -- ההסתברות שלו יורדת.

זה נשמע טריוויאלי, אבל זו הליבה של רוב המערכות המזהות
אנומליות.

**דוגמה 4 -- למה יש יותר משתמשים חוזרים מאשר חדשים**

נניח שבאתר מסוים:

-   25 אחוז מהמבקרים הם חדשים

-   75 אחוז חוזרים

מה המודל ילמד?
שהסבירות להתנהגות של "משתמש חוזר" גבוהה פי שלושה מזו של "משתמש
חדש".

במודלים התנהגותיים, הדפוס הזה משפיע על כל תחזית.

**דוגמה 5 -- למה מודל NLP נוטה להשלים מילים
מסוימות**

אם 80 אחוז מהפעמים שבהן מופיעה המילה מזג מגיע אחריה אוויר
המודל ילמד שזה "המשך טבעי".

הוא לא עושה קסמים.
הוא פשוט סופר תדירויות.

**מה המשותף לכל הדוגמאות?**

העיקרון הבסיסי חוזר שוב ושוב:
**דברים שקורים הרבה ← מקבלים משקל גבוה
דברים שקורים מעט ← מקבלים משקל נמוך**

זה הכול.
מזה נבנים מודלים שיכולים לנתח טקסט, לזהות תמונות, להמליץ על תכנים או
לנבא התנהגות.

וברגע שאתה כמפתח מתחיל לראות את העולם דרך תדירויות,
המודלים מפסיקים להיות קופסאות שחורות, והופכים לכלים שאתה מבין
באמת.

## חיבור ראשוני לעולם של סיווגים (Spam/Ham) 

עכשיו שהבנו שתדירות היא הלב של הסתברות, אפשר לראות איך זה יושב בדיוק על
אחד היישומים הכי בסיסיים בעולם ה-ML:
**סיווג (Classification).**

ברוב היישומים הראשונים של מתכנתים בעולמות ה-AI, סיווג הוא
הצעד הטבעי:
האם זה ספאם או לא?
האם הלקוח יעזוב או יישאר?
האם התמונה מכילה חתול או כלב?
האם המשפט חיובי או שלילי?

למרות שהמשימות נראות שונות לגמרי, יש להן מבנה זהה:
**המודל מקבל משהו, ומנסה לשייך אותו לאחת משתי קבוצות (או
יותר).**

וכמו שראינו בפרקים הקודמים -- השיוך הזה מבוסס על תדירויות.

**למה דווקא Spam/Ham הוא הדוגמה הכי קלאסית?**

כי זה מקרה פשוט להבנה והוא מגלה בדיוק איך המודל "חושב".

אם בתיבת הדואר שלנו:

-   1,200 הודעות מסומנות כספאם

-   800 הודעות מסומנות כרגילות

אז כבר לפני שמסתכלים על המילים בתוך ההודעות, יש עובדה
חשובה:

**הסתברות בסיסית לספאם גבוהה יותר מהסתברות בסיסית להודעה
רגילה.**

כלומר: מתוך כלל העולם שהמודל רואה
יותר דברים נופלים ל"ספאם".

וכשמודל ניגש להודעה חדשה, הוא שואל את עצמו בשקט:
\"במה זה דומה יותר למה שכבר ראיתי?\"


**איך המודל משתמש בתדירויות של מילים?**

נניח שיש לנו טבלה כמו זו:

| מילה | מופעים בספאם | מופעים בהודעות רגילות |
|------|---------------|------------------------|
| free | 42            | 3                      |
| urgent | 17         | 1                      |
| hello | 2          | 58                     |

  

המודל רואה:
**free ← כמעט תמיד בספאם**

**hello ← בדרך כלל בהודעות רגילות**

אין כאן נוסחאות מתוחכמות.
זו פשוט ספירה.

ברוב המקרים, סיווגים ראשוניים עובדים על מבנה בסיסי כזה:
הסתברות למילים מסוימות בתוך קבוצות שונות ←
תדירות ← החלטה.

**
**

**מה זה אומר למפתח בפועל?**

כשמפתחים מערכות סיווג, כדאי לשים לב ל-3 שאלות פשוטות:

1.  **מה מופיע הרבה בקבוצה מסוימת?**

2.  **מה כמעט לא מופיע?**

3.  **אילו דברים משותפים לשתי הקבוצות?**

רק מהשאלות האלה אפשר לפעמים לשפר מודל פי כמה
עוד לפני שנוגעים בקוד שלו.

**למה זה חשוב לקראת הפרק הבא?**

כי בעולם האמיתי, מודלים לא מסתפקים בידע על "כמה פעמים מילה
מופיעה".
הם רוצים לדעת:

-   מה הסיכוי למשהו **בהינתן** משהו אחר?

-   מה המשמעות של מילה בתוך הקשר?

-   איך מחשבים הסתברות כשיש שתי קבוצות עם מאפיינים שונים?

ופה בדיוק נכנסת **הסתברות מותנית**.
זה אחד הכלים החזקים ביותר בהבנת דפוסים,
ולמעשה הבסיס של משפט בייס -- שהוא בלב של כל משימות הסיווג.